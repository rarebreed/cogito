{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Learning Functional Programming: 101\n",
    "\n",
    "This document is a guide to help you learn how to think functionally in a data oriented style\n",
    "and move away from imperative, side-effectful and OOP.\n",
    "\n",
    "The lessons will cover the following topics:\n",
    "\n",
    "- Why FP and data oriented programs are the future\n",
    "- Modern type systems\n",
    "- Expressions vs. statements\n",
    "- Thinking in terms of data instead of \"Objects\"\n",
    "- What side effects are and how to encapsulate them\n",
    "- Handling errors and nulls\n",
    "- Imperative vs compostion programming\n",
    "- Advaced FP: Pure Functional programming (scala3)\n",
    "- Advanced types: Higher Kinded Types (scala3)\n",
    "- Advanced types: typeclasses (scala3)\n",
    "\n",
    "## Motvation\n",
    "\n",
    "Before starting, I wanted to go over why I wanted to create this tutorial.  I have been dabbling in \n",
    "Functional Programming for about 9 years which was when I first heard about clojure.  At the time, I was feeling frustrated with Java, but I couldn't really put my finger on _why_ I was frustrated.  At the time, I had heard about Scala being the _next_ Java, so I bought Odersky's book and started reading it.  After a couple of chapters, I gave up because there were too many \"usually\"s for my taste (like you \"usually\" didn't need to add a semi-colon which reminded me too much of Perl which I detested).  But still, Java felt wrong and I couldnt't really articulate why.\n",
    "\n",
    "Then I [read][-slides]/[watched][-video] Rich Hickey's article about State and how we were doing it all wrong.  It was an eye-opener.  I felt like I had some Hallelujah moment and a prophet was speaking to me.  Although the article was about state and how OOP got it all wrong, I was also intrigued by clojure itself, a lisp dialect.  Lisps are the first functional programming language, and the 2nd oldest of all (the oldest extant since no one does Algol anymore).  How is that a 60+ year old language is still around and kicking?  And even though clojure's light has somewhat dimmed, why was it so hot a couple years ago?\n",
    "\n",
    "Clojure helped with two banes of programmers existence:\n",
    "\n",
    "- brought some sanity to mutation of values, especially in a multithreaded context\n",
    "- reintroduced many to FP constructs including immutability, higher ordered functions, and everything is a function\n",
    "\n",
    "This tutorial will hopefully explain why FP concepts are so powerful, and whythe Java language itself is moving away from OOP.  \n",
    "\n",
    "## FP is the future\n",
    "\n",
    "It's been several years now that people have been talking about Functional Programming.  Many engineers felt threatened that their OOP skill set would become obsolete, and so there has been quite a bit of FUD being spread around whether intentional or not.  About a decade ago or less, people were saying the following to pooh-pooh on FP\n",
    "\n",
    "- It works for the Ivory Tower academics, but not us real world developers\n",
    "- OOP only fails when people dont follow its principles (encapsulation, preferring composability, etc)\n",
    "- SOLID principles makes FP unnecessary\n",
    "- OOP is intuitive, FP is for mathematicians\n",
    "- FP is only good for some problems but isn't good for others (eg, UI programming)\n",
    "- FP is so slow because you cant mutate anything\n",
    "\n",
    "There were many many things being said about FP, some of it (partially) true, but quite a bit of it was just sheer ignorance (whether unknowlingly or not, I can't say, but I do wonder how much of it was caused by people unwilling to learn something new, and toss out a skillset they spent so much time on).  For example, React followed many FP principles and showed that not only _could_ FP be used for UI programming, it was in fact probably the _best_ model.  The same could be said of redux or mobx as front end state stores for Single Page Apps.  And while it's true that FP in a single threaded context is slower than imperative \"mutate in place\" programming, immutability makes parallel programming much easier to handle (this is why goroutines in golang or kotlin coroutines are not magical bullets since the underlying data types can be mutable).\n",
    "\n",
    "I mention this FUD, because as engineers and scientists, our job is to:\n",
    "\n",
    "- Create the most efficient product possible\n",
    "- Use the least amount of engineering resources before AND after the product is shipped\n",
    "- Create a product that is not only easily testable, but easy to pinpoint where the failure is\n",
    "- Engineer the product in a manner that can be reasoned about more simply\n",
    "- Write it in a way that can be changed as easily as possible\n",
    "\n",
    "We should be _embracing_ new paradigms rather than trying to knock them down because we either don't want to learn something new or feel like our existing skillset is obsolete.  The fact of the matter is that technology is _always_ changing, and if you don;t want to learn something new, because you're an expert 10 yr veteran of technology X, but don't want to lose out to the snot-nosed kid who knows technology Y (which has advantages over X), then frankly, you are in the wrong career.\n",
    "\n",
    "As engineers and scientists, we should always keep our eyes open for new ways of doing things, and an open mind to realize any potential.  On the flip side of the coin, we can't jump on every new bandwagon because the internet thinks it is hot.  Here, I am not talking about frameworks, stacks or libraries in specific, but rather the paradigm and conceptual ideas those frameworks, stacks or libraries are built on top of.  React became such a huge hit not because it was made by Facebook, but because it actually solved a lot of pain that Angular (by Google) or jQuery did not resolve.  React solved problems not just because it had a cleaner API, or better docs, or was \"easier\".  React was built on a reactive paradigm (which is a lose relative Functional Reactive Programming), and it with redux, helped with a lot of the pain seen in front end applications when dealing with state change.\n",
    "\n",
    "## But I can solve these problems already\n",
    "\n",
    "This headline above is a common answer that many have when presented with a new way of doing things.  I believe that these engineers either think:\n",
    "\n",
    "- Coding in that style is not as productive because\n",
    "    - It's too abstract or hard to learn and get right\n",
    "    - It takes too much time to line up all your ducks in row (eg, think Haskell)\n",
    "- New technologies are unproven and not \"battle tested\"\n",
    "- Managers won't want to try it, because \"where will we find people who know this new tech?\"\n",
    "- Or Managers will think it requires whole team buy-in which is harder to do (which is true)\n",
    "- The problems being faced are exaggerated\n",
    "- The problems can be solved if engineers are just more diligent and disciplined or follow convention\n",
    "- There isn't enough 3rd party support to make it worthwhile\n",
    "\n",
    "While every paradigm has its pros and cons, we need to ask ourselves if the benefits outweigh the negatives.  So let's look at each of these claims\n",
    "\n",
    "### Productivity suffers\n",
    "\n",
    "The argument here is that if an engineer is already productive in say Java, what's the benefit to moving to Kotlin or scala3?  Afterall, the engineer will be far more productive in a language they have tons of experience with right?\n",
    "\n",
    "First, let's tackle what we _really_ mean by `productive`.  All too often, engineers and managers especially, have a very limited view of productivity.  In a narrow mindset, productivity means \"how many features can you implement or bugs can you fix per sprint?\".  The narrowness here is all too common and doesn't factor things outside of actual coding like:\n",
    "\n",
    "- Writing documentation\n",
    "    - in the small (API docs) \n",
    "    - In the large (tutorials, HLA, specs, notebooks, wikis etc)\n",
    "- Testing your code\n",
    "    - Writing unit tests and test case requirements\n",
    "    - Doing ad-hoc testing\n",
    "- Time spent debugging and triaging or responding to pager alerts\n",
    "    - Time spent creating or updating tickets like Jira or github issues\n",
    "    - Analyzing reports or APM metrics\n",
    "- Time _thinking_ about the problem and what actually needs to be done versus what is requested\n",
    "- Time spent thinking about how to make the code reusable\n",
    "- Reading other people's code\n",
    "    - Code reviews \n",
    "    - Understanding what someone else's code does to fix, refactor or use it\n",
    "- Getting your code to actually build (fighting with dependencies, maven, gradle, etc)\n",
    "- Dealing with infrastructure\n",
    "    - Getting your test fixtures or other test system infrastructure right\n",
    "    - Getting CI/CD right (jenkins jobs, ansible playbooks, custom shell scripts, deployments, etc)\n",
    "- Going to meetings or informal discussions about a feature with engineers, PM's, etc\n",
    "\n",
    "As you can see, actually coding is just one small portion of your life as an engineer. Yet, for some reason, too many people just equate \"productivity\" with how fast you can release a feature.\n",
    "\n",
    "One of the few lessons I learned in my Software Engineering class was that 80% of the time spent on a feature was after code was launched (maintenance and fixes).  Here, I am going to focus here on just 3 of the above: \n",
    "\n",
    "- Time spent debugging\n",
    "- Writing tests\n",
    "- Making code reusable\n",
    "\n",
    "I will go more deeply into how and why FP will make you more productive _in the long run_.  I will make the case that pure FP programs will be easier to reason about, easier to test, and be easier to reuse.\n",
    "\n",
    "## How OOP failed us\n",
    "\n",
    "So, let's keep an open mind and consider that we should be doing something different.  I will argue that OOP has failed us by making things more complicated than they needed to be.  Or rather, I should say OOP + Imperative programming (which is pretty much what everyone does).\n",
    "\n",
    "If you don't believe me, the Java architects themselves have explicitly stated they are moving towards a more data-oriented style of programming.  This can be seen in several new features they have made that all borrow from FP:\n",
    "\n",
    "- Record types: immutable data containers\n",
    "- Value types (Project Loom): goes hand in hand with records, and is a huge performance boost\n",
    "- Sealed types: Enums on steroids that allow you to specify a limited set of related types\n",
    "- Pattern matching: Only works with immutable types but allows destructuring and matching of data\n",
    "\n",
    "The java architects have also gone on the record admitting other failures:\n",
    "\n",
    "- Optional was a half baked way to try to manage the disaster of null\n",
    "- Checked Exceptions sounded nice in theory, but failed in practice\n",
    "- Getting the wrong defaults for many things\n",
    "\n",
    "Perhaps the biggest failing of Java is just the concept of OOP itself which Java embraced 100%.  You can't even create a standalone function without embedding it into a class.  Then there's the whole primitives/arrays vs Object divide (which Project Loom should resolve). But why did OOP fail, and why is even Java, the mid 90s champion of OOP decide to move on (as much as it can....it is hobbled by legacy support and will probably never be able to completely divorce itself)?\n",
    "\n",
    "OOP and imperative programming failed us in several ways\n",
    "\n",
    "- Side effects were paid little thought, and only pure FP languages with advanced type systems can even track side effects\n",
    "- Defaulted to mutable rather than immutable data\n",
    "- Standalone functions either had no representation at all (java <=7>) or are hobbled (java8+)\n",
    "- Imperative programming assumes synchronous programming and a sequential style\n",
    "- Exception handling was handled in its own little world, rather than being treated as a type\n",
    "\n",
    "### Side effects are an afterthought\n",
    "\n",
    "Side effects are so much an afterthought, that some engineers don't even know what the term means unless they have learned a FP language!  I wrote an article on Dev Zone and talked about misconceptions around Functional Programming.  I saw more than one comment say that \"if my code intended to change an outside variable or write to a file, that's not a side effect since my purpose was to do that!\".  Unfortunately, that's the colloquial definition of a side effect: an unintended consequence of some other action.  \n",
    "\n",
    "In Programming Language Theory, side effects has a much more precise definition.  A side effect is when a function either affects the \"outside world\" (anything out of scope of the function itself) or is affected by the outside world.  For example, any kind of IO operation like writing to a file, a network socket or even the console is a side effect.  Another more insidious side effect is time.  Time is an implicit factor of state (state is defined as \"value of an object at a point in time\"), and it is insidious because it is hidden.  Race conditions happen because of time.  A function could fail because the file that used to exist changed a millisecond ago isn't the same _now_.\n",
    "\n",
    "Side effectful functions therefore are not _pure_.  A pure function is a function that obeys a couple of laws:\n",
    "\n",
    "- It can't have side effects\n",
    "- Therefore, given the same arguments, it will always give you the same answer\n",
    "- As a consequence of the above, a pure function is immune to time (an implicit argument in side effecting functions)\n",
    "- By implication, a pure function must return something or the answer is never known\n",
    "\n",
    "Pure functions therefore are immune to the outside world and also do not disturb the outside world.  The only way to interact with a pure function is to give it inputs and recieve an output.  \n",
    "\n",
    "Think about addition.  You give addition 2 numbers, and you get back a number.  Addition doesn't mutate the numbers you put in.  It doesn't send the answer to a service which might return a 500.  It doesn't save the result to a file.  It doesn't even write the answer to STDOUT.  One could argue that if we don't have _some_ side effect, then how would we ever know what the answer was?\n",
    "\n",
    "This is entirely correct.  If you do a pure computation, you would never be able to know what the compued result was!  So at some point, you **must** do side effects.  So this is where _pure_ FP differs from regular FP.  In a pure FP environment side effects are described in the type system itself, and the main program is just some kind of type that performs IO.  The trick is safely encapsulating the pure part of the computation from the impure part.\n",
    "\n",
    "By treating side effects as a first class construct, we now know:\n",
    "\n",
    "- where it is\n",
    "- how to separate or encapsulate the pure parts from the impure parts\n",
    "\n",
    "### Immutability\n",
    "\n",
    "Going hand in hand with side effects is immutability.  One extemely popular language doesn't even _have_ the concept of immutability (cough, python, hack).  But why should we care about immutability?\n",
    "Why has it become so important in modern language design?\n",
    "\n",
    "It comes down to two things really:\n",
    "\n",
    "- Being able to reason about code when a variable cant change\n",
    "- Being safe for sharing across threads\n",
    "\n",
    "It's even unfortunate that we use the term _variable_ to denote \"things that hold a value\".  The problem is that while variable can mean \"something that can be substitued for\", we don't have a way to distinguish _how many times_ you can perform the substitution (only on initialization, or even afterwards?).  Some languages might differentiate them with a `const` or `final` modifier, or perhaps distinguishing between `val` and `var` (kotlin and scala do this), but we still call them _variables_ unfortunately.  Or even more confusingly \"constant variable\" or \"immutable variable\".  How can something be constant or immutable, and also _variable_?  \n",
    "\n",
    "This is an unfortunate legacy of programming.  Even the age old lisp called them `vars` or `defs`, but at least lisp also separated out the idea of the _name_ of variable (a `Symbol`) from the thing the symbol referred to (the data it represented).  \n",
    "\n",
    "This sleight of hand is so second nature to us, that we just think of the name of a variable as equivalent to its value.  Unfortunately, we don't really stop to think about all the machinery going on under the hood (unless you are a C(++) or rust programmer).  Consider the following in java:\n",
    "\n",
    "```java\n",
    "var name = \"Sean\";\n",
    "```\n",
    "\n",
    "Here, `name` has a string the value of which is \"Sean\".  But what is going on in the computer?  Then the variable `name` is just a reference, which is really a kind of pointer to a memory address.  This memory holds a contiguous chunk of bytes, which when decoded by utf8 comes out as \"Sean\".  What would happen if I do this?\n",
    "\n",
    "```java\n",
    "name = \"John\";\n",
    "```\n",
    "\n",
    "Java wouldn't care.  The compiler will go, oh ok, the engineer wants to change the _value_ that `name` points to.  But what does that even mean?  There are two possibilities.  The language could either:\n",
    "\n",
    "1. Change `name` to a different location in memory, where its value is \"John\"\n",
    "2. Erase the memory that `name` points to, and put \"John\" there\n",
    "\n",
    "Since `name` has a String type, and Strings are immutable in Java, Java does the first option. But what if the type wasn't immutable?  Now things get messy.  Now, the compiler will write code that might do the 2nd option.  \n",
    "\n",
    "```java\n",
    "import java.util.Set;\n",
    "\n",
    "class Person {\n",
    "    String name;\n",
    "    Integer age;\n",
    "    Set<String> languages;\n",
    "\n",
    "    public Person(String name, Integer age) {\n",
    "        this.name = name;\n",
    "        this.age = ahe;\n",
    "    }\n",
    "\n",
    "    public static void main(String... args) {\n",
    "        // How immutable data works\n",
    "        var s = \"Sean\";\n",
    "        var s2 = s;\n",
    "        s == s2; // true\n",
    "        s.hashCode();\n",
    "        s2.hashCode();\n",
    "        s = \"John\";\n",
    "        System.out.println(s2); // still prints \"Sean\"\n",
    "        s.hashCode(); // is now different\n",
    "\n",
    "        // how mutable data works\n",
    "        var p = new Person(\"Sean\", 49);\n",
    "        var p2 = p;\n",
    "\n",
    "        p == p2; // true\n",
    "        System.out.println(p.name); // \"Sean\n",
    "        System.out.println(p2.name); // also \"Sean\"\n",
    "        p.name = \"Alex\";  // What do you think p2.name is?\n",
    "        p == p3;  // true or false?\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "A source of never ending confusion is that in the example above, when you change `p.name` since `p2` is pointing to the same memory, p2.name _does_ change, and their hashcodes are still equal.  This _might_ be what you want, but more often than not, most programmers assume that p2 is just a copy of the data, and thus shouldn't change.  So already, immutable is more intuitive!\n",
    "\n",
    "And we aren't even doing multithreaded programming yet!  If you have some object, and the values inside the object can change over time, you now have to keep track of who could change the data, and when, evem in a single threaded environment.  If you forgot that that some other component had access to the object, or even part of the object, then you might be surprised when the answer doesn't come out the way you think.\n",
    "\n",
    "How about kotlin?  Is it different?\n",
    "\n",
    "```kotlin\n",
    "import \n",
    "data class Person(var name: String, val age: Int, val languages: Set<String> = setOf())\n",
    "// to make this in scala3, just do case class instead\n",
    "// case class Person(name: String, age: Int, languages: Set<String> = Set())\n",
    "\n",
    "val p = Person(\"Sean\", 49)\n",
    "val p2 = p\n",
    "p2 == p \n",
    "p.name = \"John\"\n",
    "p2 == p // true\n",
    "p2.name // \"John\n",
    "val p3 = Person(\"Sean\", 49)\n",
    "p3 == p // true because kotlin does \"value\" equality, not refernece equality\n",
    "```\n",
    "\n",
    "So we can see that kotlin and scala still \n",
    "\n",
    "It's bad enough in a single threaded environment where any field with a setter (public or private) can change your data.  Now imagine multiple threads having access.  But wait!! Isn't `private` supposed to help me by limiting who can set the value?  The problem doesn't go away with private setters.  Because the problem isn't just \"who\" changes the data, but \"when\".  Again, time is your enemy because it is almost always a hidden argument in side effectful and mutable programs.\n",
    "\n",
    "Rust, learning from the mistakes of so many languages made immutable variables the default, and you had to use a `mut` keyword to tell the compiler \"the value in memory can change in place\".  Kotlin, scala and javascript decided that there would be no default, and you had to specify if it was either mutable (`var`) or immutable (`val`).  Java, being an old-school language made mutability the default, and you have to tell java you want immutability by using the `final` modifier.  Even the Java architects admit this was a mistake.\n",
    "\n",
    "Mutability does have one advantage though: it's faster.  Changing the data in place is faster than copying the entire dataset.  Imagine an array with tens of thousands of elements.  So, mutability still has its place, but be wary of it.  Unless you are using rust, whose compiler is virtually unique in being able to guarantee us that only one owner can ever modify a value at one time, even in a multithreaded environment.  Performance and safety: that's why rust is so loved.  But, this tutorial is mostly for those of stuck in GC'ed languages.\n",
    "\n",
    "[-video]: https://www.infoq.com/presentations/Are-We-There-Yet-Rich-Hickey/\n",
    "[-slides]: http://wiki.jvmlangsummit.com/images/a/ab/HickeyJVMSummit2009.pdf"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "kotlin"
  },
  "kernelspec": {
   "name": "python388jvsc74a57bd0e8216c222367b888d255e6c9a35219f628d8aa495f0588f39a54654cb07e9204",
   "display_name": "Kotlin",
   "language": "kotlin"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}